{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3469001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbde720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example sentences (10) ---\n",
    "sentences = [\n",
    "    \"This movie was amazing and inspiring\",\n",
    "    \"I hated the film, it was boring\",\n",
    "    \"The acting was brilliant\",\n",
    "    \"Terrible direction and poor editing\",\n",
    "    \"Loved every minute of it\",\n",
    "    \"The plot was weak and predictable\",\n",
    "    \"Fantastic music and visuals\",\n",
    "    \"Not worth watching\",\n",
    "    \"Absolutely wonderful experience\",\n",
    "    \"Disappointing performance overall\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67900f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', 'movie', 'was', 'amazing', 'and', 'inspiring'],\n",
       " ['i', 'hated', 'the', 'film,', 'it', 'was', 'boring'],\n",
       " ['the', 'acting', 'was', 'brilliant'],\n",
       " ['terrible', 'direction', 'and', 'poor', 'editing'],\n",
       " ['loved', 'every', 'minute', 'of', 'it'],\n",
       " ['the', 'plot', 'was', 'weak', 'and', 'predictable'],\n",
       " ['fantastic', 'music', 'and', 'visuals'],\n",
       " ['not', 'worth', 'watching'],\n",
       " ['absolutely', 'wonderful', 'experience'],\n",
       " ['disappointing', 'performance', 'overall']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 1) Tokenize (very simple tokenizer)\n",
    "# -------------------------\n",
    "tokenized = [s.lower().split() for s in sentences]\n",
    "# Example: tokenized[0] == [\"this\",\"movie\",\"was\",\"amazing\",\"and\",\"inspiring\"]\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 2) Build a vocabulary (simple)\n",
    "# -------------------------\n",
    "# special tokens\n",
    "PAD = \"<pad>\"\n",
    "UNK = \"<unk>\"\n",
    "\n",
    "# collect tokens and build mapping\n",
    "counter = Counter(tok for sent in tokenized for tok in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4779af3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 39 (including PAD and UNK)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " '<unk>',\n",
       " 'absolutely',\n",
       " 'acting',\n",
       " 'amazing',\n",
       " 'and',\n",
       " 'boring',\n",
       " 'brilliant',\n",
       " 'direction',\n",
       " 'disappointing',\n",
       " 'editing',\n",
       " 'every',\n",
       " 'experience',\n",
       " 'fantastic',\n",
       " 'film,',\n",
       " 'hated',\n",
       " 'i',\n",
       " 'inspiring',\n",
       " 'it',\n",
       " 'loved',\n",
       " 'minute',\n",
       " 'movie',\n",
       " 'music',\n",
       " 'not',\n",
       " 'of',\n",
       " 'overall',\n",
       " 'performance',\n",
       " 'plot',\n",
       " 'poor',\n",
       " 'predictable',\n",
       " 'terrible',\n",
       " 'the',\n",
       " 'this',\n",
       " 'visuals',\n",
       " 'was',\n",
       " 'watching',\n",
       " 'weak',\n",
       " 'wonderful',\n",
       " 'worth']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep all tokens for this tiny example; in real tasks you may limit vocabulary size\n",
    "vocab_tokens = [PAD, UNK] + sorted(counter.keys())\n",
    "print(f\"Vocab size: {len(vocab_tokens)} (including PAD and UNK)\")\n",
    "vocab_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3a190dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'<pad>': 0,\n",
       "  '<unk>': 1,\n",
       "  'absolutely': 2,\n",
       "  'acting': 3,\n",
       "  'amazing': 4,\n",
       "  'and': 5,\n",
       "  'boring': 6,\n",
       "  'brilliant': 7,\n",
       "  'direction': 8,\n",
       "  'disappointing': 9,\n",
       "  'editing': 10,\n",
       "  'every': 11,\n",
       "  'experience': 12,\n",
       "  'fantastic': 13,\n",
       "  'film,': 14,\n",
       "  'hated': 15,\n",
       "  'i': 16,\n",
       "  'inspiring': 17,\n",
       "  'it': 18,\n",
       "  'loved': 19,\n",
       "  'minute': 20,\n",
       "  'movie': 21,\n",
       "  'music': 22,\n",
       "  'not': 23,\n",
       "  'of': 24,\n",
       "  'overall': 25,\n",
       "  'performance': 26,\n",
       "  'plot': 27,\n",
       "  'poor': 28,\n",
       "  'predictable': 29,\n",
       "  'terrible': 30,\n",
       "  'the': 31,\n",
       "  'this': 32,\n",
       "  'visuals': 33,\n",
       "  'was': 34,\n",
       "  'watching': 35,\n",
       "  'weak': 36,\n",
       "  'wonderful': 37,\n",
       "  'worth': 38},\n",
       " {0: '<pad>',\n",
       "  1: '<unk>',\n",
       "  2: 'absolutely',\n",
       "  3: 'acting',\n",
       "  4: 'amazing',\n",
       "  5: 'and',\n",
       "  6: 'boring',\n",
       "  7: 'brilliant',\n",
       "  8: 'direction',\n",
       "  9: 'disappointing',\n",
       "  10: 'editing',\n",
       "  11: 'every',\n",
       "  12: 'experience',\n",
       "  13: 'fantastic',\n",
       "  14: 'film,',\n",
       "  15: 'hated',\n",
       "  16: 'i',\n",
       "  17: 'inspiring',\n",
       "  18: 'it',\n",
       "  19: 'loved',\n",
       "  20: 'minute',\n",
       "  21: 'movie',\n",
       "  22: 'music',\n",
       "  23: 'not',\n",
       "  24: 'of',\n",
       "  25: 'overall',\n",
       "  26: 'performance',\n",
       "  27: 'plot',\n",
       "  28: 'poor',\n",
       "  29: 'predictable',\n",
       "  30: 'terrible',\n",
       "  31: 'the',\n",
       "  32: 'this',\n",
       "  33: 'visuals',\n",
       "  34: 'was',\n",
       "  35: 'watching',\n",
       "  36: 'weak',\n",
       "  37: 'wonderful',\n",
       "  38: 'worth'},\n",
       " 0,\n",
       " 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mappings\n",
    "word2idx = {w: i for i, w in enumerate(vocab_tokens)}\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "\n",
    "pad_idx = word2idx[PAD]\n",
    "unk_idx = word2idx[UNK]\n",
    "\n",
    "word2idx, idx2word, pad_idx, unk_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bec6856f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded indices shape: torch.Size([10, 7])\n",
      "Example padded row (first sentence): [32, 21, 34, 4, 5, 17, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[32, 21, 34,  4,  5, 17,  0],\n",
       "        [16, 15, 31, 14, 18, 34,  6],\n",
       "        [31,  3, 34,  7,  0,  0,  0],\n",
       "        [30,  8,  5, 28, 10,  0,  0],\n",
       "        [19, 11, 20, 24, 18,  0,  0],\n",
       "        [31, 27, 34, 36,  5, 29,  0],\n",
       "        [13, 22,  5, 33,  0,  0,  0],\n",
       "        [23, 38, 35,  0,  0,  0,  0],\n",
       "        [ 2, 37, 12,  0,  0,  0,  0],\n",
       "        [ 9, 26, 25,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 3) Numericalize (tokens -> indices) and pad into a batch\n",
    "# -------------------------\n",
    "encoded = []\n",
    "for sent in tokenized:\n",
    "    ids = [word2idx.get(tok, unk_idx) for tok in sent]\n",
    "    encoded.append(torch.tensor(ids, dtype=torch.long))\n",
    "\n",
    "# pad_sequence will create a (batch_size, max_len) tensor when batch_first=True\n",
    "padded = pad_sequence(encoded, batch_first=True, padding_value=pad_idx)\n",
    "# padded.shape -> (10, max_len)\n",
    "print(\"Padded indices shape:\", padded.shape)\n",
    "print(\"Example padded row (first sentence):\", padded[0].tolist())\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e02b2f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings shape: torch.Size([10, 7, 50])\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 4) Embedding layer (word embeddings)\n",
    "# -------------------------\n",
    "embedding_dim = 50\n",
    "emb = nn.Embedding(num_embeddings=len(vocab_tokens), embedding_dim=embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "# get word embeddings: shape -> (batch_size, seq_len, embedding_dim)\n",
    "word_embeds = emb(padded)\n",
    "print(\"Word embeddings shape:\", word_embeds.shape)  # e.g. (10, max_len, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ad9f54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings shape: torch.Size([10, 50])\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 5) Convert to sentence embeddings (mean pooling ignoring padding)\n",
    "# -------------------------\n",
    "# create mask for non-padding tokens: shape (batch_size, seq_len, 1)\n",
    "mask = (padded != pad_idx).unsqueeze(-1).float()  # 1 where real token, 0 where PAD\n",
    "\n",
    "# zero out padding embeddings and sum\n",
    "sum_embeds = (word_embeds * mask).sum(dim=1)  # shape (batch_size, embedding_dim)\n",
    "# count real tokens per sentence\n",
    "lengths = mask.sum(dim=1)  # shape (batch_size, 1)\n",
    "lengths = lengths.clamp(min=1)  # avoid division by zero\n",
    "sent_embeds = sum_embeds / lengths  # mean over non-pad tokens\n",
    "print(\"Sentence embeddings shape:\", sent_embeds.shape)  # (10, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a09737b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example outputs ---\n",
      "Vocabulary sample: [('<pad>', 0), ('<unk>', 1), ('absolutely', 2), ('acting', 3), ('amazing', 4), ('and', 5), ('boring', 6), ('brilliant', 7)]\n",
      "First sentence tokens: ['this', 'movie', 'was', 'amazing', 'and', 'inspiring']\n",
      "First sentence indices: [32, 21, 34, 4, 5, 17, 0]\n",
      "First sentence embedding vector (size): torch.Size([50])\n",
      "First 6 values of first sentence embedding: [0.033360760658979416, 0.3194434344768524, -1.1688367128372192, -1.0341030359268188, 0.09556436538696289, -0.027250101789832115]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 6) Inspect results\n",
    "# -------------------------\n",
    "print(\"\\n--- Example outputs ---\")\n",
    "print(\"Vocabulary sample:\", list(word2idx.items())[:8])\n",
    "print(\"First sentence tokens:\", tokenized[0])\n",
    "print(\"First sentence indices:\", padded[0].tolist())\n",
    "print(\"First sentence embedding vector (size):\", sent_embeds[0].shape)\n",
    "print(\"First 6 values of first sentence embedding:\", sent_embeds[0][:6].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0da5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09176582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ffd68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
